(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{176:function(t,a,r){"use strict";r.r(a);var i=r(0),e=Object(i.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,a=t.$createElement,r=t._self._c||a;return r("div",{staticClass:"content"},[r("h1",{attrs:{id:"加载数据"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#加载数据","aria-hidden":"true"}},[t._v("#")]),t._v(" 加载数据")]),t._v(" "),r("h2",{attrs:{id:"选择提取方法"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#选择提取方法","aria-hidden":"true"}},[t._v("#")]),t._v(" 选择提取方法")]),t._v(" "),r("p",[t._v("Druid支持流式（实时）和基于文件（批量）的数据提取方式。最常用的配置是：")]),t._v(" "),r("ul",[r("li",[r("strong",[t._v("Files")]),t._v(": 通过HDFS、S3、本地文件或者任何支持hadoop文件系统批量加载数据。如果你的数据集已经在这类文件系统中推荐使用这个方法。")]),t._v(" "),r("li",[r("strong",[t._v("Stream push")]),t._v(": 使用Tranquility（向Druid发送流的客户端）将实时数据流推送到Druid。如果你的数据集来自于流式系统，如Kafka, Storm, Spark Streaming或者自建的流系统，推荐使用此方法。")]),t._v(" "),r("li",[r("strong",[t._v("Stream pull")]),t._v(": 使用实时节点直接从外部数据源将数据流拉入Druid。")])]),t._v(" "),r("h2",{attrs:{id:"入门"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#入门","aria-hidden":"true"}},[t._v("#")]),t._v(" 入门")]),t._v(" "),r("p",[t._v("最简单的方式是通过学习下面三个教程来开始加载自己的数据：")]),t._v(" "),r("ul",[r("li",[t._v("基于文件的教程，介绍如何通过本地磁盘加载数据。")]),t._v(" "),r("li",[t._v("基于streams的教程，介绍如何通过HTTP推送数据。")]),t._v(" "),r("li",[t._v("基于kafka的教程，介绍如何从kafka加载数据。")])]),t._v(" "),r("h2",{attrs:{id:"批处理、流式混合模式"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#批处理、流式混合模式","aria-hidden":"true"}},[t._v("#")]),t._v(" 批处理、流式混合模式")]),t._v(" "),r("p",[t._v("在batch/streaming架构中，你可以混合使用批处理、流式的方法。在混合（Hybrid ）模式中，您可以使用流式方法来执行初次提取，然后以批处理方式定期提取旧数据（通常是每几小时或者夜维）。当Druid重新获取时间范围内的数据时，新数据会自动替换早期提取的数据。\n在某些故障情况下，当下所有的Druid流式数据传输方法都会导致数据的丢失或重复。通过批量重新摄取数据可以消除历史数据中的这种潜在的威胁。\n如果您因任何原因需要修改数据，则批量重新提取还可让您重新提取数据。")])])}],!1,null,null,null);e.options.__file="加载数据.md";a.default=e.exports}}]);